{"title": "Evaluating the efficacy of AI content detection tools in differentiating between human and AI-generated text", "year": 2023, "authors": "Ahmed M. Elkhatat, Khaled Elsaid, S. Almeer", "url": "https://api.semanticscholar.org/CorpusId:261398391", "relevance": 3, "abstract": "The proliferation of artificial intelligence (AI)-generated content, particularly from models like ChatGPT, presents potential challenges to academic integrity and raises concerns about plagiarism. This study investigates the capabilities of various AI content detection tools in discerning human and AI-authored content. Fifteen paragraphs each from ChatGPT Models 3.5 and 4 on the topic of cooling towers in the engineering process and five human-witten control responses were generated for evaluation. AI content detection tools developed by OpenAI, Writer, Copyleaks, GPTZero, and CrossPlag were used to evaluate these paragraphs. Findings reveal that the AI detection tools were more accurate in identifying content generated by GPT 3.5 than GPT 4. However, when applied to human-written control responses, the tools exhibited inconsistencies, producing false positives and uncertain classifications. This study underscores the need for further development and refinement of AI content detection tools as AI-generated content becomes more sophisticated and harder to distinguish from human-written text.", "citations": 271}
{"title": "DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text", "year": 2023, "authors": "Xianjun Yang, Wei Cheng, Linda Petzold, William Yang Wang, Haifeng Chen", "url": "https://api.semanticscholar.org/CorpusId:258960101", "relevance": 3, "abstract": "Large language models (LLMs) have notably enhanced the fluency and diversity of machine-generated text. However, this progress also presents a significant challenge in detecting the origin of a given text, and current research on detection methods lags behind the rapid evolution of LLMs. Conventional training-based methods have limitations in flexibility, particularly when adapting to new domains, and they often lack explanatory power. To address this gap, we propose a novel training-free detection strategy called Divergent N-Gram Analysis (DNA-GPT). Given a text, we first truncate it in the middle and then use only the preceding portion as input to the LLMs to regenerate the new remaining parts. By analyzing the differences between the original and new remaining parts through N-gram analysis in black-box or probability divergence in white-box, we unveil significant discrepancies between the distribution of machine-generated text and the distribution of human-written text. We conducted extensive experiments on the most advanced LLMs from OpenAI, including text-davinci-003, GPT-3.5-turbo, and GPT-4, as well as open-source models such as GPT-NeoX-20B and LLaMa-13B. Results show that our zero-shot approach exhibits state-of-the-art performance in distinguishing between human and GPT-generated text on four English and one German dataset, outperforming OpenAI's own classifier, which is trained on millions of text. Additionally, our methods provide reasonable explanations and evidence to support our claim, which is a unique feature of explainable detection. Our method is also robust under the revised text attack and can additionally solve model sourcing. Codes are available at https://github.com/Xianjun-Yang/DNA-GPT.", "citations": 148}
{"title": "MGTBench: Benchmarking Machine-Generated Text Detection", "year": 2023, "authors": "Xinlei He, Xinyue Shen, Zeyuan Chen, M. Backes, Yang Zhang", "url": "https://www.semanticscholar.org/paper/e7ba478aad9b9534a9f632b85ad87177f5587189", "relevance": 3, "abstract": "Nowadays, powerful large language models (LLMs) such as ChatGPT have demonstrated revolutionary power in a variety of natural language processing (NLP) tasks such as text classification, sentiment analysis, language translation, and question-answering. Consequently, the detection of machine-generated texts (MGTs) is becoming increasingly crucial as LLMs become more advanced and prevalent. These models have the ability to generate human-like language, making it challenging to discern whether a text is authored by a human or a machine. This raises concerns regarding authenticity, accountability, and potential bias. However, existing methods for detecting MGTs are evaluated using different model architectures, datasets, and experimental settings, resulting in a lack of a comprehensive evaluation framework that encompasses various methodologies. Furthermore, it remains unclear how existing detection methods would perform against powerful LLMs. In this paper, we fill this gap by proposing the first benchmark framework for MGT detection against powerful LLMs, named MGTBench. Extensive evaluations on public datasets with curated texts generated by various powerful LLMs such as ChatGPT-turbo and Claude demonstrate the effectiveness of different detection methods. Our ablation study shows that a larger number of words in general leads to better performance and most detection methods can achieve similar performance with much fewer training samples. Additionally, our findings reveal that metric-based/model-based detection methods exhibit better transferability across different LLMs/datasets. Furthermore, we delve into a more challenging task: text attribution, where the goal is to identify the originating model of a given text, i.e., whether it is a specific LLM or authored by a human. Our findings indicate that the model-based detection methods still perform well in the text attribution task. To investigate the robustness of different detection methods, we consider three adversarial attacks, namely paraphrasing, random spacing, and adversarial perturbations. We discover that these attacks can significantly diminish detection effectiveness, underscoring the critical need for the development of more robust detection methods. We envision that MGTBench will serve as a benchmark tool to accelerate future investigations involving the evaluation of powerful MGT detection methods on their respective datasets and the development of more advanced MGT detection methods.", "citations": 141}
{"title": "Ghostbuster: Detecting Text Ghostwritten by Large Language Models", "year": 2023, "authors": "V. Verma, Eve Fleisig, Nicholas Tomlin, D. Klein", "url": "https://api.semanticscholar.org/CorpusId:258865787", "relevance": 3, "abstract": "We introduce Ghostbuster, a state-of-the-art system for detecting AI-generated text.Our method works by passing documents through a series of weaker language models, running a structured search over possible combinations of their features, and then training a classifier on the selected features to predict whether documents are AI-generated.Crucially, Ghostbuster does not require access to token probabilities from the target model, making it useful for detecting text generated by black-box or unknown models.In conjunction with our model, we release three new datasets of human- and AI-generated text as detection benchmarks in the domains of student essays, creative writing, and news articles. We compare Ghostbuster to several existing detectors, including DetectGPT and GPTZero, as well as a new RoBERTa baseline. Ghostbuster achieves 99.0 F1 when evaluated across domains, which is 5.9 F1 higher than the best preexisting model. It also outperforms all previous approaches in generalization across writing domains (+7.5 F1), prompting strategies (+2.1 F1), and language models (+4.4 F1). We also analyze our system\u2019s robustness to a variety of perturbations and paraphrasing attacks, and evaluate its performance on documents by non-native English speakers.", "citations": 102}
{"title": "RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors", "year": 2024, "authors": "Liam Dugan, Alyssa Hwang, Filip Trhlik, Josh Magnus Ludan, Andrew Zhu, Hainiu Xu, Daphne Ippolito, Christopher Callison-Burch", "url": "https://api.semanticscholar.org/CorpusId:269757699", "relevance": 3, "abstract": "Many commercial and open-source models claim to detect machine-generated text with extremely high accuracy (99% or more). However, very few of these detectors are evaluated on shared benchmark datasets and even when they are, the datasets used for evaluation are insufficiently challenging-lacking variations in sampling strategy, adversarial attacks, and open-source generative models. In this work we present RAID: the largest and most challenging benchmark dataset for machine-generated text detection. RAID includes over 6 million generations spanning 11 models, 8 domains, 11 adversarial attacks and 4 decoding strategies. Using RAID, we evaluate the out-of-domain and adversarial robustness of 8 open- and 4 closed-source detectors and find that current detectors are easily fooled by adversarial attacks, variations in sampling strategies, repetition penalties, and unseen generative models. We release our data along with a leaderboard to encourage future research.", "citations": 110}
{"title": "ArguGPT: evaluating, understanding and identifying argumentative essays generated by GPT models", "year": 2023, "authors": "Yikang Liu, Ziyin Zhang, Wanyang Zhang, Shisen Yue, Xiaojing Zhao, Xinyuan Cheng, Yiwen Zhang, Hai Hu", "url": "https://api.semanticscholar.org/CorpusId:258179137", "relevance": 3, "abstract": "AI generated content (AIGC) presents considerable challenge to educators around the world. Instructors need to be able to detect such text generated by large language models, either with the naked eye or with the help of some tools. There is also growing need to understand the lexical, syntactic and stylistic features of AIGC. To address these challenges in English language teaching, we first present ArguGPT, a balanced corpus of 4,038 argumentative essays generated by 7 GPT models in response to essay prompts from three sources: (1) in-class or homework exercises, (2) TOEFL and (3) GRE writing tasks. Machine-generated texts are paired with roughly equal number of human-written essays with three score levels matched in essay prompts. We then hire English instructors to distinguish machine essays from human ones. Results show that when first exposed to machine-generated essays, the instructors only have an accuracy of 61% in detecting them. But the number rises to 67% after one round of minimal self-training. Next, we perform linguistic analyses of these essays, which show that machines produce sentences with more complex syntactic structures while human essays tend to be lexically more complex. Finally, we test existing AIGC detectors and build our own detectors using SVMs and RoBERTa. Results suggest that a RoBERTa fine-tuned with the training set of ArguGPT achieves above 90% accuracy in both essay- and sentence-level classification. To the best of our knowledge, this is the first comprehensive analysis of argumentative essays produced by generative large language models. Machine-authored essays in ArguGPT and our models will be made publicly available at https://github.com/huhailinguist/ArguGPT", "citations": 78}
{"title": "Classification of Human- and AI-Generated Texts: Investigating Features for ChatGPT", "year": 2023, "authors": "Lorenz Mindner, Tim Schlippe, Kristina Schaaff", "url": "https://www.semanticscholar.org/paper/4a166004de99191be6dc7338fed4d78f246c8904", "relevance": 3, "abstract": "Recently, generative AIs like ChatGPT have become available to the wide public. These tools can for instance be used by students to generate essays or whole theses. But how does a teacher know whether a text is written by a student or an AI? In our work, we explore traditional and new features to (1) detect text generated by AI from scratch and (2) text rephrased by AI. Since we found that classification is more difficult when the AI has been instructed to create the text in a way that a human would not recognize that it was generated by an AI, we also investigate this more advanced case. For our experiments, we produced a new text corpus covering 10 school topics. Our best systems to classify basic and advanced human-generated/AI-generated texts have F1-scores of over 96%. Our best systems for classifying basic and advanced human-generated/AI-rephrased texts have F1-scores of more than 78%. The systems use a combination of perplexity, semantic, list lookup, error-based, readability, AI feedback, and text vector features. Our results show that the new features substantially help to improve the performance of many classifiers. Our best basic text rephrasing detection system even outperforms GPTZero by 183.8% relative in F1-score.", "citations": 68}
{"title": "GPTZero Performance in Identifying Artificial Intelligence-Generated Medical Texts: A Preliminary Study", "year": 2023, "authors": "F. Habibzadeh", "url": "https://api.semanticscholar.org/CorpusId:261978383", "relevance": 3, "abstract": "Background With emergence of chatbots to help authors with scientific writings, editors should have tools to identify artificial intelligence-generated texts. GPTZero is among the first websites that has sought media attention claiming to differentiate machine-generated from human-written texts. Methods Using 20 text pieces generated by ChatGPT in response to arbitrary questions on various topics in medicine and 30 pieces chosen from previously published medical articles, the performance of GPTZero was assessed. Results GPTZero had a sensitivity of 0.65 (95% confidence interval, 0.41\u20130.85); specificity, 0.90 (0.73\u20130.98); accuracy, 0.80 (0.66\u20130.90); and positive and negative likelihood ratios, 6.5 (2.1\u201319.9) and 0.4 (0.2\u20130.7), respectively. Conclusion GPTZero has a low false-positive (classifying a human-written text as machine-generated) and a high false-negative rate (classifying a machine-generated text as human-written).", "citations": 50}
{"title": "An Empirical Study of AI Generated Text Detection Tools", "year": 2023, "authors": "Arslan Akram", "url": "https://api.semanticscholar.org/CorpusId:249635702", "relevance": 3, "abstract": "Since ChatGPT has emerged as a major AIGC model, providing high-quality responses across a wide range of applications (including software development and maintenance), it has attracted much interest from many individuals. ChatGPT has great promise, but there are serious problems that might arise from its misuse, especially in the realms of education and public safety. Several AIGC detectors are available, and they have all been tested on genuine text. However, more study is needed to see how effective they are for multi-domain ChatGPT material. This study aims to fill this need by creating a multi-domain dataset for testing the state-of-the-art APIs and tools for detecting artificially generated information used by universities and other research institutions. A large dataset consisting of articles, abstracts, stories, news, and product reviews was created for this study. The second step is to use the newly created dataset to put six tools through their paces. Six different artificial intelligence (AI) text identification systems, including \"GPTkit,\" \"GPTZero,\" \"Originality,\" \"Sapling,\" \"Writer,\" and \"Zylalab,\" have accuracy rates between 55.29 and 97.0%. Although all the tools fared well in the evaluations, originality was particularly effective across the board.", "citations": 51}
{"title": "AI-Generated Text Detector for Arabic Language Using Encoder-Based Transformer Architecture", "year": 2024, "authors": "Hamed Alshammari, Ahmed El-Sayed, Khaled Elleithy", "url": "https://www.semanticscholar.org/paper/12379da6c8e9f28c70929b737e8b73a314adbbc5", "relevance": 3, "abstract": "The effectiveness of existing AI detectors is notably hampered when processing Arabic texts. This study introduces a novel AI text classifier designed specifically for Arabic, tackling the distinct challenges inherent in processing this language. A particular focus is placed on accurately recognizing human-written texts (HWTs), an area where existing AI detectors have demonstrated significant limitations. To achieve this goal, this paper utilized and fine-tuned two Transformer-based models, AraELECTRA and XLM-R, by training them on two distinct datasets: a large dataset comprising 43,958 examples and a custom dataset with 3078 examples that contain HWT and AI-generated texts (AIGTs) from various sources, including ChatGPT 3.5, ChatGPT-4, and BARD. The proposed architecture is adaptable to any language, but this work evaluates these models\u2019 efficiency in recognizing HWTs versus AIGTs in Arabic as an example of Semitic languages. The performance of the proposed models has been compared against the two prominent existing AI detectors, GPTZero and OpenAI Text Classifier, particularly on the AIRABIC benchmark dataset. The results reveal that the proposed classifiers outperform both GPTZero and OpenAI Text Classifier with 81% accuracy compared to 63% and 50% for GPTZero and OpenAI Text Classifier, respectively. Furthermore, integrating a Dediacritization Layer prior to the classification model demonstrated a significant enhancement in the detection accuracy of both HWTs and AIGTs. This Dediacritization step markedly improved the classification accuracy, elevating it from 81% to as high as 99% and, in some instances, even achieving 100%.", "citations": 21}
{"title": "Technical Report on the Pangram AI-Generated Text Classifier", "year": 2024, "authors": "Bradley Emi, Max Spero", "url": "https://api.semanticscholar.org/CorpusId:267897841", "relevance": 3, "abstract": "We present Pangram Text, a transformer-based neural network trained to distinguish text written by large language models from text written by humans. Pangram Text outperforms zero-shot methods such as DetectGPT as well as leading commercial AI detection tools with over 38 times lower error rates on a comprehensive benchmark comprised of 10 text domains (student writing, creative writing, scientific writing, books, encyclopedias, news, email, scientific papers, short-form Q&A) and 8 open- and closed-source large language models. We propose a training algorithm, hard negative mining with synthetic mirrors, that enables our classifier to achieve orders of magnitude lower false positive rates on high-data domains such as reviews. Finally, we show that Pangram Text is not biased against nonnative English speakers and generalizes to domains and models unseen during training.", "citations": 19}
{"title": "Classification of human- and AI-generated texts for different languages and domains", "year": 2024, "authors": "Kristina Schaaff, Tim Schlippe, Lorenz Mindner", "url": "https://api.semanticscholar.org/CorpusId:274519398", "relevance": 3, "abstract": "Chatbots based on large language models (LLMs) like ChatGPT are available to the wide public. These tools can for instance be used by students to generate essays or whole theses from scratch or by rephrasing an existing text. But how does for instance a teacher know whether a text is written by a student or an AI? In this paper, we investigate perplexity, semantic, list lookup, document, error-based, readability, AI feedback and text vector features to classify human-generated and AI-generated texts from the educational domain as well as news articles. We analyze two scenarios: (1) The detection of text generated by AI from scratch, and (2) the detection of text rephrased by AI. Since we assumed that classification is more difficult when the AI has been prompted to create or rephrase the text in a way that a human would not recognize that it was generated or rephrased by an AI, we also investigate this advanced prompting scenario. To train, fine-tune and test the classifiers, we created the Multilingual Human-AI-Generated Text Corpus which contains human-generated, AI-generated and AI-rephrased texts from the educational domain in English, French, German, and Spanish and English texts from the news domain. We demonstrate that the same features can be used for the detection of AI-generated and AI-rephrased texts from the educational domain in all languages and the detection of AI-generated and AI-rephrased news texts. Our best systems significantly outperform GPTZero and ZeroGPT\u2014state-of-the-art systems for the detection of AI-generated text. Our best text rephrasing detection system even outperforms GPTZero by 181.3% relative in F1-score.", "citations": 10}
{"title": "Detecting Machine-Generated Texts: Not Just \"AI vs Humans\" and Explainability is Complicated", "year": 2024, "authors": "Jiazhou Ji, Ruizhe Li, Shujun Li, Jie Guo, Weidong Qiu, Zheng Huang, Chiyu Chen, Xiaoyu Jiang, Xinru Lu", "url": "https://api.semanticscholar.org/CorpusId:270738035", "relevance": 3, "abstract": "As LLMs rapidly advance, increasing concerns arise regarding risks about actual authorship of texts we see online and in real world. The task of distinguishing LLM-authored texts is complicated by the nuanced and overlapping behaviors of both machines and humans. In this paper, we challenge the current practice of considering LLM-generated text detection a binary classification task of differentiating human from AI. Instead, we introduce a novel ternary text classification scheme, adding an\"undecided\"category for texts that could be attributed to either source, and we show that this new category is crucial to understand how to make the detection result more explainable to lay users. This research shifts the paradigm from merely classifying to explaining machine-generated texts, emphasizing need for detectors to provide clear and understandable explanations to users. Our study involves creating four new datasets comprised of texts from various LLMs and human authors. Based on new datasets, we performed binary classification tests to ascertain the most effective SOTA detection methods and identified SOTA LLMs capable of producing harder-to-detect texts. We constructed a new dataset of texts generated by two top-performing LLMs and human authors, and asked three human annotators to produce ternary labels with explanation notes. This dataset was used to investigate how three top-performing SOTA detectors behave in new ternary classification context. Our results highlight why\"undecided\"category is much needed from the viewpoint of explainability. Additionally, we conducted an analysis of explainability of the three best-performing detectors and the explanation notes of the human annotators, revealing insights about the complexity of explainable detection of machine-generated texts. Finally, we propose guidelines for developing future detection systems with improved explanatory power.", "citations": 16}
{"title": "Zero-Shot Detection of Machine-Generated Codes", "year": 2023, "authors": "Xianjun Yang, Kexun Zhang, Haifeng Chen, L. Petzold, William Yang Wang, Wei Cheng", "url": "https://api.semanticscholar.org/CorpusId:263831381", "relevance": 3, "abstract": "This work proposes a training-free approach for the detection of LLMs-generated codes, mitigating the risks associated with their indiscriminate usage. To the best of our knowledge, our research is the first to investigate zero-shot detection techniques applied to code generated by advanced black-box LLMs like ChatGPT. Firstly, we find that existing training-based or zero-shot text detectors are ineffective in detecting code, likely due to the unique statistical properties found in code structures. We then modify the previous zero-shot text detection method, DetectGPT (Mitchell et al., 2023) by utilizing a surrogate white-box model to estimate the probability of the rightmost tokens, allowing us to identify code snippets generated by language models. Through extensive experiments conducted on the python codes of the CodeContest and APPS dataset, our approach demonstrates its effectiveness by achieving state-of-the-art detection results on text-davinci-003, GPT-3.5, and GPT-4 models. Moreover, our method exhibits robustness against revision attacks and generalizes well to Java codes. We also find that the smaller code language model like PolyCoder-160M performs as a universal code detector, outperforming the billion-scale counterpart. The codes will be available at https://github.com/ Xianjun-Yang/Code_detection.git", "citations": 28}
{"title": "AuthorMist: Evading AI Text Detectors with Reinforcement Learning", "year": 2025, "authors": "Isaac David, Arthur Gervais", "url": "https://api.semanticscholar.org/CorpusId:276937603", "relevance": 3, "abstract": "In the age of powerful AI-generated text, automatic detectors have emerged to identify machine-written content. This poses a threat to author privacy and freedom, as text authored with AI assistance may be unfairly flagged. We propose AuthorMist, a novel reinforcement learning-based system to transform AI-generated text into human-like writing. AuthorMist leverages a 3-billion-parameter language model as a backbone, fine-tuned with Group Relative Policy Optimization (GPRO) to paraphrase text in a way that evades AI detectors. Our framework establishes a generic approach where external detector APIs (GPTZero, WinstonAI, Originality.ai, etc.) serve as reward functions within the reinforcement learning loop, enabling the model to systematically learn outputs that these detectors are less likely to classify as AI-generated. This API-as-reward methodology can be applied broadly to optimize text against any detector with an accessible interface. Experiments on multiple datasets and detectors demonstrate that AuthorMist effectively reduces the detectability of AI-generated text while preserving the original meaning. Our evaluation shows attack success rates ranging from 78.6% to 96.2% against individual detectors, significantly outperforming baseline paraphrasing methods. AuthorMist maintains high semantic similarity (above 0.94) with the original text while successfully evading detection. These results highlight limitations in current AI text detection technologies and raise questions about the sustainability of the detection-evasion arms race.", "citations": 5}
{"title": "Who Said That? Benchmarking Social Media AI Detection", "year": 2023, "authors": "Wanyun Cui, Linqiu Zhang, Qianle Wang, Shuyang Cai", "url": "https://api.semanticscholar.org/CorpusId:263909042", "relevance": 3, "abstract": "AI-generated text has proliferated across various online platforms, offering both transformative prospects and posing significant risks related to misinformation and manipulation. Addressing these challenges, this paper introduces SAID (Social media AI Detection), a novel benchmark developed to assess AI-text detection models' capabilities in real social media platforms. It incorporates real AI-generate text from popular social media platforms like Zhihu and Quora. Unlike existing benchmarks, SAID deals with content that reflects the sophisticated strategies employed by real AI users on the Internet which may evade detection or gain visibility, providing a more realistic and challenging evaluation landscape. A notable finding of our study, based on the Zhihu dataset, reveals that annotators can distinguish between AI-generated and human-generated texts with an average accuracy rate of 96.5%. This finding necessitates a re-evaluation of human capability in recognizing AI-generated text in today's widely AI-influenced environment. Furthermore, we present a new user-oriented AI-text detection challenge focusing on the practicality and effectiveness of identifying AI-generated text based on user information and multiple responses. The experimental results demonstrate that conducting detection tasks on actual social media platforms proves to be more challenging compared to traditional simulated AI-text detection, resulting in a decreased accuracy. On the other hand, user-oriented AI-generated text detection significantly improve the accuracy of detection.", "citations": 13}
{"title": "Classification of Human- and AI-Generated Texts for English, French, German, and Spanish", "year": 2023, "authors": "Kristina Schaaff, Tim Schlippe, Lorenz Mindner", "url": "https://api.semanticscholar.org/CorpusId:266149905", "relevance": 3, "abstract": "In this paper we analyze features to classify human- and AI-generated text for English, French, German and Spanish and compare them across languages. We investigate two scenarios: (1) The detection of text generated by AI from scratch, and (2) the detection of text rephrased by AI. For training and testing the classifiers in this multilingual setting, we created a new text corpus covering 10 topics for each language. For the detection of AI-generated text, the combination of all proposed features performs best, indicating that our features are portable to other related languages: The F1-scores are close with 99% for Spanish, 98% for English, 97% for German and 95% for French. For the detection of AI-rephrased text, the systems with all features outperform systems with other features in many cases, but using only document features performs best for German (72%) and Spanish (86%) and only text vector features leads to best results for English (78%).", "citations": 10}
{"title": "Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays", "year": 2025, "authors": "Selin Dik, Osman Erdem, Mehmet Dik", "url": "https://api.semanticscholar.org/CorpusId:280012442", "relevance": 3, "abstract": "As the use of AI tools by students has become more prevalent, instructors have started using AI detection tools like GPTZero and QuillBot to detect AI written text. However, the reliability of these detectors remains uncertain. In our study, we focused mostly on the success rate of GPTZero, the most-used AI detector, in identifying AI-generated texts based on different lengths of randomly submitted essays: short (40-100 word count), medium (100-350 word count), and long (350-800 word count). We gathered a data set consisting of twenty-eight AI-generated papers and fifty human-written papers. With this randomized essay data, papers were individually plugged into GPTZero and measured for percentage of AI generation and confidence. A vast majority of the AI-generated papers were detected accurately (ranging from 91-100% AI believed generation), while the human generated essays fluctuated; there were a handful of false positives. These findings suggest that although GPTZero is effective at detecting purely AI-generated content, its reliability in distinguishing human-authored texts is limited. Educators should therefore exercise caution when relying solely on AI detection tools.", "citations": 0}
{"title": "Evaluating the Performance of AI Text Detectors, Few-Shot and Chain-of-Thought Prompting Using DeepSeek Generated Text", "year": 2025, "authors": "Hulayyil Alshammari, Praveen Rao", "url": "https://api.semanticscholar.org/CorpusId:280017630", "relevance": 3, "abstract": "Large language models (LLMs) have rapidly transformed the creation of written materials. LLMs have led to questions about writing integrity, thereby driving the creation of artificial intelligence (AI) detection technologies. Adversarial attacks, such as standard and humanized paraphrasing, inhibit detectors'ability to detect machine-generated text. Previous studies have mainly focused on ChatGPT and other well-known LLMs and have shown varying accuracy across detectors. However, there is a clear gap in the literature about DeepSeek, a recently published LLM. Therefore, in this work, we investigate whether six generally accessible AI detection tools -- AI Text Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, and GPTZero -- can consistently recognize text generated by DeepSeek. The detectors were exposed to the aforementioned adversarial attacks. We also considered DeepSeek as a detector by performing few-shot prompting and chain-of-thought reasoning (CoT) for classifying AI and human-written text. We collected 49 human-authored question-answer pairs from before the LLM era and generated matching responses using DeepSeek-v3, producing 49 AI-generated samples. Then, we applied adversarial techniques such as paraphrasing and humanizing to add 196 more samples. These were used to challenge detector robustness and assess accuracy impact. While QuillBot and Copyleaks showed near-perfect performance on original and paraphrased DeepSeek text, others -- particularly AI Text Classifier and GPT-2 -- showed inconsistent results. The most effective attack was humanization, reducing accuracy to 71% for Copyleaks, 58% for QuillBot, and 52% for GPTZero. Few-shot and CoT prompting showed high accuracy, with the best five-shot result misclassifying only one of 49 samples (AI recall 96%, human recall 100%).", "citations": 0}
{"title": "Detecting LLM-Generated Short Answers and Effects on Learner Performance", "year": 2025, "authors": "Shambhavi Bhushan, Danielle R. Thomas, Conrad Borchers, Isha Raghuvanshi, Ralph Abboud, Erin Gatz, Shivang Gupta, Ken Koedinger", "url": "https://api.semanticscholar.org/CorpusId:279465305", "relevance": 3, "abstract": "The increasing availability of large language models (LLMs) has raised concerns about their potential misuse in online learning. While tools for detecting LLM-generated text exist and are widely used by researchers and educators, their reliability varies. Few studies have compared the accuracy of detection methods, defined criteria to identify content generated by LLM, or evaluated the effect on learner performance from LLM misuse within learning. In this study, we define LLM-generated text within open responses as those produced by any LLM without paraphrasing or refinement, as evaluated by human coders. We then fine-tune GPT-4o to detect LLM-generated responses and assess the impact on learning from LLM misuse. We find that our fine-tuned LLM outperforms the existing AI detection tool GPTZero, achieving an accuracy of 80% and an F1 score of 0.78, compared to GPTZero's accuracy of 70% and macro F1 score of 0.50, demonstrating superior performance in detecting LLM-generated responses. We also find that learners suspected of LLM misuse in the open response question were more than twice as likely to correctly answer the corresponding posttest MCQ, suggesting potential misuse across both question types and indicating a bypass of the learning process. We pave the way for future work by demonstrating a structured, code-based approach to improve LLM-generated response detection and propose using auxiliary statistical indicators such as unusually high assessment scores on related tasks, readability scores, and response duration. In support of open science, we contribute data and code to support the fine-tuning of similar models for similar use cases.", "citations": 0}
{"title": "Leveraging Explainable AI for LLM Text Attribution: Differentiating Human-Written and Multiple LLMs-Generated Text", "year": 2025, "authors": "Ayat Najjar, Huthaifa I. Ashqar, O. A. Darwish, Eman M. Hammad", "url": "https://api.semanticscholar.org/CorpusId:275337238", "relevance": 3, "abstract": "The development of generative AI Large Language Models (LLMs) raised the alarm regarding the identification of content produced by generative AI vs. humans. In one case, issues arise when students heavily rely on such tools in a manner that can affect the development of their writing or coding skills. Other issues of plagiarism also apply. This study aims to support efforts to detect and identify textual content generated using LLM tools. We hypothesize that LLM-generated text is detectable by machine learning (ML) and investigate ML models that can recognize and differentiate between texts generated by humans and multiple LLM tools. We used a dataset of student-written text in comparison with LLM-written text. We leveraged several ML and Deep Learning (DL) algorithms, such as Random Forest (RF) and Recurrent Neural Networks (RNNs) and utilized Explainable Artificial Intelligence (XAI) to understand the important features in attribution. Our method is divided into (1) binary classification to differentiate between human-written and AI-generated text and (2) multi-classification to differentiate between human-written text and text generated by five different LLM tools (ChatGPT, LLaMA, Google Bard, Claude, and Perplexity). Results show high accuracy in multi- and binary classification. Our model outperformed GPTZero (78.3%), with an accuracy of 98.5%. Notably, GPTZero was unable to recognize about 4.2% of the observations, but our model was able to recognize the complete test dataset. XAI results showed that understanding feature importance across different classes enables detailed author/source profiles, aiding in attribution and supporting plagiarism detection by highlighting unique stylistic and structural elements, thereby ensuring robust verification of content originality.", "citations": 6}
{"title": "People who frequently use ChatGPT for writing tasks are accurate and robust detectors of AI-generated text", "year": 2025, "authors": "Jenna Russell, Marzena Karpinska, Mohit Iyyer", "url": "https://api.semanticscholar.org/CorpusId:275921918", "relevance": 3, "abstract": "In this paper, we study how well humans can detect text generated by commercial LLMs (GPT-4o, Claude, o1). We hire annotators to read 300 non-fiction English articles, label them as either human-written or AI-generated, and provide paragraph-length explanations for their decisions. Our experiments show that annotators who frequently use LLMs for writing tasks excel at detecting AI-generated text, even without any specialized training or feedback. In fact, the majority vote among five such\"expert\"annotators misclassifies only 1 of 300 articles, significantly outperforming most commercial and open-source detectors we evaluated even in the presence of evasion tactics like paraphrasing and humanization. Qualitative analysis of the experts' free-form explanations shows that while they rely heavily on specific lexical clues ('AI vocabulary'), they also pick up on more complex phenomena within the text (e.g., formality, originality, clarity) that are challenging to assess for automatic detectors. We release our annotated dataset and code to spur future research into both human and automated detection of AI-generated text.", "citations": 29}
{"title": "Assessing LLM Text Detection in Educational Contexts: Does Human Contribution Affect Detection?", "year": 2025, "authors": "Lukas Gehring, Benjamin Paa\u00dfen", "url": "https://api.semanticscholar.org/CorpusId:280566216", "relevance": 3, "abstract": "Recent advancements in Large Language Models (LLMs) and their increased accessibility have made it easier than ever for students to automatically generate texts, posing new challenges for educational institutions. To enforce norms of academic integrity and ensure students'learning, learning analytics methods to automatically detect LLM-generated text appear increasingly appealing. This paper benchmarks the performance of different state-of-the-art detectors in educational contexts, introducing a novel dataset, called Generative Essay Detection in Education (GEDE), containing over 900 student-written essays and over 12,500 LLM-generated essays from various domains. To capture the diversity of LLM usage practices in generating text, we propose the concept of contribution levels, representing students'contribution to a given assignment. These levels range from purely human-written texts, to slightly LLM-improved versions, to fully LLM-generated texts, and finally to active attacks on the detector by\"humanizing\"generated texts. We show that most detectors struggle to accurately classify texts of intermediate student contribution levels, like LLM-improved human-written texts. Detectors are particularly likely to produce false positives, which is problematic in educational settings where false suspicions can severely impact students'lives. Our dataset, code, and additional supplementary materials are publicly available at https://github.com/lukasgehring/Assessing-LLM-Text-Detection-in-Educational-Contexts.", "citations": 2}
{"title": "The accuracy-bias trade-offs in AI text detection tools and their impact on fairness in scholarly publication", "year": 2025, "authors": "Ahmad R. Pratama", "url": "https://api.semanticscholar.org/CorpusId:279814370", "relevance": 3, "abstract": "Artificial intelligence (AI) text detection tools are considered a means of preserving the integrity of scholarly publication by identifying whether a text is written by humans or generated by AI. This study evaluates three popular tools (GPTZero, ZeroGPT, and DetectGPT) through two experiments: first, distinguishing human-written abstracts from those generated by ChatGPT o1 and Gemini 2.0 Pro Experimental; second, evaluating AI-assisted abstracts where the original text has been enhanced by these large language models (LLMs) to improve readability. Results reveal notable trade-offs in accuracy and bias, disproportionately affecting non-native speakers and certain disciplines. This study highlights the limitations of detection-focused approaches and advocates a shift toward ethical, responsible, and transparent use of LLMs in scholarly publication.", "citations": 5}
{"title": "Determining the best feature combination through text and probabilistic feature analysis for GPT-2-based mobile app review detection", "year": 2023, "authors": "Seung-Cheol Lee, Dong-Gun Lee, Yeong-Seok Seo", "url": "https://api.semanticscholar.org/CorpusId:266588421", "relevance": 3, "abstract": "Mobile apps, used by many people worldwide, have become an essential part of life. Before using a mobile app, users judge the reliability of apps according to their reviews. Therefore, app reviews are essential components of management for companies. Unfortunately, some fake reviewers write negative reviews for competing apps. Moreover, artificial intelligence (AI)-based macro bot programs that generate app reviews have emerged and can create large numbers of reviews with malicious purposes in a short time. One notable AI technology that can generate such reviews is Generative Pre-trained Transformer-2 (GPT-2). The reviews generated by GPT-2 use human-like grammar; therefore, it is difficult to detect them with only text mining techniques, which use tools like part-of-speech (POS) tagging and sentiment scores. Thus, probability-based sampling techniques in GPT-2 must be used. In this study, we identified features to detect reviews generated by GPT-2 and determined the optimal feature combination for improving detection performance. To achieve this, based on the analysis results, we built a training dataset to find the best feature combination for detecting the generated reviews. Various machine learning models were then trained and evaluated using this dataset. As a result, the model that used both text mining and probability-based sampling techniques detected generated reviews more effectively than the model that used only text mining techniques. This model achieved a top classification accuracy of 90% and a macro F1 of 0.90. We expect the results of this study to help app developers maintain a more stable mobile app ecosystem.", "citations": 9}
{"title": "Automatic Detection of LLM-Generated Code: A Comparative Case Study of Contemporary Models Across Function and Class Granularities", "year": 2024, "authors": "Musfiqur Rahman, S. Khatoonabadi, Ahmad Abdellatif, Emad Shihab", "url": "https://api.semanticscholar.org/CorpusId:284077854", "relevance": 3, "abstract": "The adoption of Large Language Models (LLMs) for code generation risks incorporating vulnerable code into software systems. Existing detectors face two critical limitations: a lack of systematic cross-model validation and opaque\"black box\"operation. We address this through a comparative study of code generated by four distinct LLMs: GPT-3.5, Claude 3 Haiku, Claude Haiku 4.5, and GPT-OSS. Analyzing 14,485 Python functions and 11,913 classes from the CodeSearchNet dataset, we generated corresponding code with all four LLMs. Using interpretable software metrics, we trained CatBoost classifiers for each configuration. Our analysis reveals that granularity effects dominate model differences by a factor of 8.6, with negligible feature overlap, indicating that function-level and class-level detection rely on fundamentally disjoint structural signatures. We discover critical granularity-dependent inversions: while modern models (Claude, GPT-OSS) are more detectable at the class level, GPT-3.5 is an anomaly that uniquely excels at the function level. SHAP analysis identifies the Comment-to-Code Ratio as the sole universal discriminator. However, its predictive magnitude varies drastically across models, explaining why detectors trained on specific LLMs fail to generalize. Our findings demonstrate that GPT-3.5's exceptional detectability (AUC-ROC 0.96) is unrepresentative of contemporary models (AUC-ROC approximately between 0.68 and 0.80). Robust detection requires moving beyond single-model studies to account for substantial diversity in structural fingerprints across architectures and granularities.", "citations": 0}
{"title": "Evaluating AIGC Detectors on Code Content", "year": 2023, "authors": "Jian Wang, Shangqing Liu, Xiaofei Xie, Yi Li", "url": "https://api.semanticscholar.org/CorpusId:258060085", "relevance": 3, "abstract": "Artificial Intelligence Generated Content (AIGC) has garnered considerable attention for its impressive performance, with ChatGPT emerging as a leading AIGC model that produces high-quality responses across various applications, including software development and maintenance. Despite its potential, the misuse of ChatGPT poses significant concerns, especially in education and safetycritical domains. Numerous AIGC detectors have been developed and evaluated on natural language data. However, their performance on code-related content generated by ChatGPT remains unexplored. To fill this gap, in this paper, we present the first empirical study on evaluating existing AIGC detectors in the software domain. We created a comprehensive dataset including 492.5K samples comprising code-related content produced by ChatGPT, encompassing popular software activities like Q&A (115K), code summarization (126K), and code generation (226.5K). We evaluated six AIGC detectors, including three commercial and three open-source solutions, assessing their performance on this dataset. Additionally, we conducted a human study to understand human detection capabilities and compare them with the existing AIGC detectors. Our results indicate that AIGC detectors demonstrate lower performance on code-related data compared to natural language data. Fine-tuning can enhance detector performance, especially for content within the same domain; but generalization remains a challenge. The human evaluation reveals that detection by humans is quite challenging.", "citations": 22}
{"title": "Are We in the AI-Generated Text World Already? Quantifying and Monitoring AIGT on Social Media", "year": 2024, "authors": "Zhen Sun, Zongmin Zhang, Xinyue Shen, Ziyi Zhang, Yule Liu, Michael Backes, Yang Zhang, Xinlei He", "url": "https://api.semanticscholar.org/CorpusId:274992622", "relevance": 3, "abstract": "Social media platforms are experiencing a growing presence of AI-Generated Texts (AIGTs). However, the misuse of AIGTs could have profound implications for public opinion, such as spreading misinformation and manipulating narratives. Despite its importance, it remains unclear how prevalent AIGTs are on social media. To address this gap, this paper aims to quantify and monitor the AIGTs on online social media platforms. We first collect a dataset (SM-D) with around 2.4M posts from 3 major social media platforms: Medium, Quora, and Reddit. Then, we construct a diverse dataset (AIGTBench) to train and evaluate AIGT detectors. AIGTBench combines popular open-source datasets and our AIGT datasets generated from social media texts by 12 LLMs, serving as a benchmark for evaluating mainstream detectors. With this setup, we identify the best-performing detector (OSM-Det). We then apply OSM-Det to SM-D to track AIGTs across social media platforms from January 2022 to October 2024, using the AI Attribution Rate (AAR) as the metric. Specifically, Medium and Quora exhibit marked increases in AAR, rising from 1.77% to 37.03% and 2.06% to 38.95%, respectively. In contrast, Reddit shows slower growth, with AAR increasing from 1.31% to 2.45% over the same period. Our further analysis indicates that AIGTs on social media differ from human-written texts across several dimensions, including linguistic patterns, topic distributions, engagement levels, and the follower distribution of authors. We envision our analysis and findings on AIGTs in social media can shed light on future research in this domain.", "citations": 19}
{"title": "Uncovering LLM-Generated Code: A Zero-Shot Synthetic Code Detector via Code Rewriting", "year": 2024, "authors": "Tong Ye, Yangkai Du, Tengfei Ma, Lingfei Wu, Xuhong Zhang, Shouling Ji, Wenhai Wang", "url": "https://api.semanticscholar.org/CorpusId:270063331", "relevance": 3, "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in generating code. However, the misuse of LLM-generated (synthetic) code has raised concerns in both educational and industrial contexts, underscoring the urgent need for synthetic code detectors. Existing methods for detecting synthetic content are primarily designed for general text and struggle with code due to the unique grammatical structure of programming languages and the presence of numerous ``low-entropy'' tokens. Building on this, our work proposes a novel zero-shot synthetic code detector based on the similarity between the original code and its LLM-rewritten variants. Our method is based on the observation that differences between LLM-rewritten and original code tend to be smaller when the original code is synthetic. We utilize self-supervised contrastive learning to train a code similarity model and evaluate our approach on two synthetic code detection benchmarks. Our results demonstrate a significant improvement over existing SOTA synthetic content detectors, delivering notable gains in both performance and robustness on the APPS and MBPP benchmarks.", "citations": 18}
{"title": "Toward Robust Arabic AI-Generated Text Detection: Tackling Diacritics Challenges", "year": 2024, "authors": "Hamed Alshammari, Khaled Elleithy", "url": "https://api.semanticscholar.org/CorpusId:271308480", "relevance": 3, "abstract": "Current AI detection systems often struggle to distinguish between Arabic human-written text (HWT) and AI-generated text (AIGT) due to the small marks present above and below the Arabic text called diacritics. This study introduces robust Arabic text detection models using Transformer-based pre-trained models, specifically AraELECTRA, AraBERT, XLM-R, and mBERT. Our primary goal is to detect AIGTs in essays and overcome the challenges posed by the diacritics that usually appear in Arabic religious texts. We created several novel datasets with diacritized and non-diacritized texts comprising up to 9666 HWT and AIGT training examples. We aimed to assess the robustness and effectiveness of the detection models on out-of-domain (OOD) datasets to assess their generalizability. Our detection models trained on diacritized examples achieved up to 98.4% accuracy compared to GPTZero\u2019s 62.7% on the AIRABIC benchmark dataset. Our experiments reveal that, while including diacritics in training enhances the recognition of the diacritized HWTs, duplicating examples with and without diacritics is inefficient despite the high accuracy achieved. Applying a dediacritization filter during evaluation significantly improved model performance, achieving optimal performance compared to both GPTZero and the detection models trained on diacritized examples but evaluated without dediacritization. Although our focus was on Arabic due to its writing challenges, our detector architecture is adaptable to any language.", "citations": 9}
{"title": "Large Language Models and Arabic Content: A Review", "year": 2025, "authors": "Haneh Rhel, D. Roussinov", "url": "https://api.semanticscholar.org/CorpusId:278534497", "relevance": 3, "abstract": "Over the past three years, the rapid advancement of Large Language Models (LLMs) has had a profound impact on multiple areas of Artificial Intelligence (AI), particularly in Natural Language Processing (NLP) across diverse languages, including Arabic. Although Arabic is considered one of the most widely spoken languages across 27 countries in the Arabic world and used as a second language in some other non-Arabic countries as well, there is still a scarcity of Arabic resources, datasets, and tools. Arabic NLP tasks face various challenges due to the complexities of the Arabic language, including its rich morphology, intricate structure, and diverse writing standards, among other factors. Researchers have been actively addressing these challenges, demonstrating that pre-trained Large Language Models (LLMs) trained on multilingual corpora achieve significant success in various Arabic NLP tasks. This study provides an overview of using large language models (LLMs) for the Arabic language, highlighting early pre-trained Arabic Language models across various NLP applications and their ability to handle diverse Arabic content tasks and dialects. It also provides an overview of how techniques like finetuning and prompt engineering can enhance the performance of these models. Additionally, the study summarizes common Arabic benchmarks and datasets while presenting our observations on the persistent upward trend in the adoption of LLMs.", "citations": 7}
{"title": "AIRABIC: Arabic Dataset for Performance Evaluation of AI Detectors", "year": 2023, "authors": "Hamed Alshammari, Ahmed EI-Sayed", "url": "https://www.semanticscholar.org/paper/4ba8059b068a4ec7d45f897cc4003dda987c8ee9", "relevance": 3, "abstract": "In the rapid expansion of Large Language Models (LLMs), such as ChatGPT, AI-generated text detection models have made substantial advancements, marking meaningful progress in several research and industrial applications. However, the performance of these models in the Semitic languages' context, especially regarding diacritic usage, continues to be inadequately explored. One of these Semitic languages that is still commonly used is Arabic language. To study the performance of the recent AI-generated text detection models on the Arabic language, this paper introduces the AIRABIC dataset, a combination of 1000 examples encompassing 500 human-written passages from 41 unique sources and an equal number of AI-generated texts from the OpenAI's Generative Pre-trained Transformer version 3.5 (GPT-3.5 Turbo ChatGPT). This study focuses on the performance evaluation of two prominent AI-generated text detectors, GPTZero and OpenAI's Text Classifier. Our findings reveal that GPTZero achieves an overall accuracy rate of 62.6%, while the OpenAI Text Classifier exhibits a 50% rate of biased categorizations when analyzing human-written text. Further analysis shows the design gaps of these detectors, especially for identifying human-written Arabic text, mainly when diacritics are involved. The detection accuracy for human-written texts with diacritics is as low as 30% for GPTZero and 0% for the OpenAI Text Classifier. Results also show the potential of diacritics to reduce the detectors' accuracy and the need to handle them in the detectors' design process.", "citations": 10}
{"title": "When Detection Fails: The Power of Fine-Tuned Models to Generate Human-Like Social Media Text", "year": 2025, "authors": "Hillary Dawkins, Kathleen C. Fraser, Svetlana Kiritchenko", "url": "https://api.semanticscholar.org/CorpusId:279306168", "relevance": 3, "abstract": "Detecting AI-generated text is a difficult problem to begin with; detecting AI-generated text on social media is made even more difficult due to the short text length and informal, idiosyncratic language of the internet. It is nonetheless important to tackle this problem, as social media represents a significant attack vector in online influence campaigns, which may be bolstered through the use of mass-produced AI-generated posts supporting (or opposing) particular policies, decisions, or events. We approach this problem with the mindset and resources of a reasonably sophisticated threat actor, and create a dataset of 505,159 AI-generated social media posts from a combination of open-source, closed-source, and fine-tuned LLMs, covering 11 different controversial topics. We show that while the posts can be detected under typical research assumptions about knowledge of and access to the generating models, under the more realistic assumption that an attacker will not release their fine-tuned model to the public, detectability drops dramatically. This result is confirmed with a human study. Ablation experiments highlight the vulnerability of various detection algorithms to fine-tuned LLMs. This result has implications across all detection domains, since fine-tuning is a generally applicable and realistic LLM use case.", "citations": 2}
{"title": "Benchmarking of LLM Detection: Comparing Two Competing Approaches", "year": 2024, "authors": "Thorsten Pr\u00f6hl, Erik Putzier, R\u00fcdiger Zarnekow", "url": "https://api.semanticscholar.org/CorpusId:270559095", "relevance": 3, "abstract": "This article gives an overview of the field of LLM text recognition. Different approaches and implemented detectors for the recognition of LLM-generated text are presented. In addition to discussing the implementations, the article focuses on benchmarking the detectors. Although there are numerous software products for the recognition of LLM-generated text, with a focus on ChatGPT-like LLMs, the quality of the recognition (recognition rate) is not clear. Furthermore, while it can be seen that scientific contributions presenting their novel approaches strive for some kind of comparison with other approaches, the construction and independence of the evaluation dataset is often not comprehensible. As a result, discrepancies in the performance evaluation of LLM detectors are often visible due to the different benchmarking datasets. This article describes the creation of an evaluation dataset and uses this dataset to investigate the different detectors. The selected detectors are benchmarked against each other.", "citations": 3}
{"title": "Signal Watermark on Large Language Models", "year": 2024, "authors": "Zhenyu Xu, Victor S. Sheng", "url": "https://api.semanticscholar.org/CorpusId:273228395", "relevance": 3, "abstract": "As Large Language Models (LLMs) become increasingly sophisticated, they raise significant security concerns, including the creation of fake news and academic misuse. Most detectors for identifying model-generated text are limited by their reliance on variance in perplexity and burstiness, and they require substantial computational resources. In this paper, we proposed a watermarking method embedding a specific watermark into the text during its generation by LLMs, based on a pre-defined signal pattern. This technique not only ensures the watermark's invisibility to humans but also maintains the quality and grammatical integrity of model-generated text. We utilize LLMs and Fast Fourier Transform (FFT) for token probability computation and detection of the signal watermark. The unique application of signal processing principles within the realm of text generation by LLMs allows for subtle yet effective embedding of watermarks, which do not compromise the quality or coherence of the generated text. Our method has been empirically validated across multiple LLMs, consistently maintaining high detection accuracy, even with variations in temperature settings during text generation. In the experiment of distinguishing between human-written and watermarked text, our method achieved an AUROC score of 0.97, significantly outperforming existing methods like GPTZero, which scored 0.64. The watermark's resilience to various attacking scenarios further confirms its robustness, addressing significant challenges in model-generated text authentication.", "citations": 2}
{"title": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking", "year": 2025, "authors": "Abolfazl Ansari, Delvin Ce Zhang, Nafis Irtiza Tripto, Dongwon Lee", "url": "https://api.semanticscholar.org/CorpusId:280561659", "relevance": 3, "abstract": "The rapid rise of Generative AI (GenAI), particularly LLMs, poses concerns for journalistic integrity and authorship. This study examines AI-generated content across over 40,000 news articles from major, local, and college news media, in various media formats. Using three advanced AI-text detectors (e.g., Binoculars, Fast-Detect GPT, and GPTZero), we find substantial increase of GenAI use in recent years, especially in local and college news. Sentence-level analysis reveals LLMs are often used in the introduction of news, while conclusions usually written manually. Linguistic analysis shows GenAI boosts word richness and readability but lowers formality, leading to more uniform writing styles, particularly in local media.", "citations": 1}
{"title": "Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts", "year": 2023, "authors": "Eduard Tulchinskii, Kristian Kuznetsov, Laida Kushnareva, D. Cherniavskii, S. Barannikov, Irina Piontkovskaya, S. Nikolenko, Evgeny Burnaev", "url": "https://api.semanticscholar.org/CorpusId:259108779", "relevance": 2, "abstract": "Rapidly increasing quality of AI-generated content makes it difficult to distinguish between human and AI-generated texts, which may lead to undesirable consequences for society. Therefore, it becomes increasingly important to study the properties of human texts that are invariant over different text domains and varying proficiency of human writers, can be easily calculated for any language, and can robustly separate natural and AI-generated texts regardless of the generation model and sampling method. In this work, we propose such an invariant for human-written texts, namely the intrinsic dimensionality of the manifold underlying the set of embeddings for a given text sample. We show that the average intrinsic dimensionality of fluent texts in a natural language is hovering around the value $9$ for several alphabet-based languages and around $7$ for Chinese, while the average intrinsic dimensionality of AI-generated texts for each language is $\\approx 1.5$ lower, with a clear statistical separation between human-generated and AI-generated distributions. This property allows us to build a score-based artificial text detector. The proposed detector's accuracy is stable over text domains, generator models, and human writer proficiency levels, outperforming SOTA detectors in model-agnostic and cross-domain scenarios by a significant margin.", "citations": 123}
{"title": "Anatomy of an AI-powered malicious social botnet", "year": 2023, "authors": "Kai-Cheng Yang, F. Menczer", "url": "https://api.semanticscholar.org/CorpusId:260334464", "relevance": 2, "abstract": "Large language models (LLMs) exhibit impressive capabilities in generating realistic text across diverse subjects. Concerns have been raised that they could be utilized to produce fake content with a deceptive intention, although evidence thus far remains anecdotal. This paper presents a case study about a Twitter botnet that appears to employ ChatGPT to generate human-like content. Through heuristics, we identify 1,140 accounts and validate them via manual annotation. These accounts form a dense cluster of fake personas that exhibit similar behaviors, including posting machine-generated content and stolen images, and engage with each other through replies and retweets. ChatGPT-generated content promotes suspicious websites and spreads harmful comments. While the accounts in the AI botnet can be detected through their coordination patterns, current state-of-the-art LLM content classifiers fail to discriminate between them and human accounts in the wild. These findings highlight the threats posed by AI-enabled social bots.", "citations": 89}
{"title": "Large Language Models can be Guided to Evade AI-Generated Text Detection", "year": 2023, "authors": "Ning Lu, Shengcai Liu, Ruidan He, Ke Tang", "url": "https://api.semanticscholar.org/CorpusId:258762215", "relevance": 2, "abstract": "Large language models (LLMs) have shown remarkable performance in various tasks and have been extensively utilized by the public. However, the increasing concerns regarding the misuse of LLMs, such as plagiarism and spamming, have led to the development of multiple detectors, including fine-tuned classifiers and statistical methods. In this study, we equip LLMs with prompts, rather than relying on an external paraphraser, to evaluate the vulnerability of these detectors. We propose a novel Substitution-based In-Context example Optimization method (SICO) to automatically construct prompts for evading the detectors. SICO is cost-efficient as it requires only 40 human-written examples and a limited number of LLM inferences to generate a prompt. Moreover, once a task-specific prompt has been constructed, it can be universally used against a wide range of detectors. Extensive experiments across three real-world tasks demonstrate that SICO significantly outperforms the paraphraser baselines and enables GPT-3.5 to successfully evade six detectors, decreasing their AUC by 0.5 on average. Furthermore, a comprehensive human evaluation show that the SICO-generated text achieves human-level readability and task completion rates, while preserving high imperceptibility. Finally, we propose an ensemble approach to enhance the robustness of detectors against SICO attack. The code is publicly available at https://github.com/ColinLu50/Evade-GPT-Detector.", "citations": 69}
{"title": "Deep learning detection method for large language models-generated scientific content", "year": 2024, "authors": "Bushra Alhijawi, Rawan Jarrar, Aseel AbuAlRub, Arwa Bader", "url": "https://api.semanticscholar.org/CorpusId:268231050", "relevance": 2, "abstract": "Large Language Models (LLMs), such as GPT-3 and BERT, reshape how textual content is written and communicated. These models can generate indistinguishable scientific content from human-authored work, raising concerns within the scientific community. Mitigating the risk of LLM-facilitated research fabrication and disseminating falsified data and results requires robust safeguards to maintain the integrity of scientific publications. This research paper presents a novel ChatGPT-generated scientific text detection method, AI-Catcher. AI-Catcher integrates two deep learning models, multilayer perceptron (MLP) and convolutional neural networks (CNN). The MLP learns the feature representations of the linguistic and statistical features. The CNN extracts high-level representations of the sequential patterns from the textual content. The proposed model fuses hidden patterns derived from MLP and CNN. AI-Catcher is a multimodal model trained using linguistic and statistical features and textual content. In addition, a new ChatGPT-Generated scientific text dataset, AIGTxt, has been collected to enhance AI-generated text detection tools. AIGTxt contains 3000 records collected from published academic articles across ten domains and divided into three classes: Human-written, ChatGPT-generated, and Mixed text. Several experiments are conducted to evaluate the performance of AI-Catcher. The comparative results demonstrate the capability of AI-Catcher to distinguish between human-written and ChatGPT-generated scientific text more accurately than alternative methods. On average, AI-Catcher improved accuracy by 37.4%.", "citations": 19}
{"title": "DUPE: Detection Undermining via Prompt Engineering for Deepfake Text", "year": 2024, "authors": "James Weichert, Chinecherem Dimobi", "url": "https://api.semanticscholar.org/CorpusId:269188351", "relevance": 2, "abstract": "As large language models (LLMs) become increasingly commonplace, concern about distinguishing between human and AI text increases as well. The growing power of these models is of particular concern to teachers, who may worry that students will use LLMs to write school assignments. Facing a technology with which they are unfamiliar, teachers may turn to publicly-available AI text detectors. Yet the accuracy of many of these detectors has not been thoroughly verified, posing potential harm to students who are falsely accused of academic dishonesty. In this paper, we evaluate three different AI text detectors-Kirchenbauer et al. watermarks, ZeroGPT, and GPTZero-against human and AI-generated essays. We find that watermarking results in a high false positive rate, and that ZeroGPT has both high false positive and false negative rates. Further, we are able to significantly increase the false negative rate of all detectors by using ChatGPT 3.5 to paraphrase the original AI-generated texts, thereby effectively bypassing the detectors.", "citations": 3}
{"title": "Is this Snippet Written by ChatGPT? An Empirical Study with a CodeBERT-Based Classifier", "year": 2023, "authors": "P. T. Nguyen, Juri Di Rocco, Claudio Di Sipio, Riccardo Rubei, D. D. Ruscio, M. D. Penta", "url": "https://api.semanticscholar.org/CorpusId:259950759", "relevance": 2, "abstract": "Since its launch in November 2022, ChatGPT has gained popularity among users, especially programmers who use it as a tool to solve development problems. However, while offering a practical solution to programming problems, ChatGPT should be mainly used as a supporting tool (e.g., in software education) rather than as a replacement for the human being. Thus, detecting automatically generated source code by ChatGPT is necessary, and tools for identifying AI-generated content may need to be adapted to work effectively with source code. This paper presents an empirical study to investigate the feasibility of automated identification of AI-generated code snippets, and the factors that influence this ability. To this end, we propose a novel approach called GPTSniffer, which builds on top of CodeBERT to detect source code written by AI. The results show that GPTSniffer can accurately classify whether code is human-written or AI-generated, and outperforms two baselines, GPTZero and OpenAI Text Classifier. Also, the study shows how similar training data or a classification context with paired snippets helps to boost classification performances.", "citations": 8}
{"title": "Beyond checkmate: exploring the creative chokepoints in AI text", "year": 2025, "authors": "Nafis Irtiza Tripto, Saranya Venkatraman, Mahjabin Nahar, Dongwon Lee", "url": "https://api.semanticscholar.org/CorpusId:276079410", "relevance": 2, "abstract": "The rapid advancement of Large Language Models (LLMs) has revolutionized text generation but also raised concerns about potential misuse, making detecting LLM-generated text (AI text) increasingly essential. While prior work has focused on identifying AI text and effectively checkmating it, our study investigates a less-explored territory: portraying the nuanced distinctions between human and AI texts across text segments (introduction, body, and conclusion). Whether LLMs excel or falter in incorporating linguistic ingenuity across text segments, the results will critically inform their viability and boundaries as effective creative assistants to humans. Through an analogy with the structure of chess games, comprising opening, middle, and end games, we analyze segment-specific patterns to reveal where the most striking differences lie. Although AI texts closely resemble human writing in the body segment due to its length, deeper analysis shows a higher divergence in features dependent on the continuous flow of language, making it the most informative segment for detection. Additionally, human texts exhibit greater stylistic variation across segments, offering a new lens for distinguishing them from AI. Overall, our findings provide fresh insights into human-AI text differences and pave the way for more effective and interpretable detection strategies. Codes available at https://github.com/tripto03/chess_inspired_human_ai_text_distinction.", "citations": 2}
{"title": "LLM Detectors Still Fall Short of Real World: Case of LLM-Generated Short News-Like Posts", "year": 2024, "authors": "Henrique Da Silva Gameiro, Andrei Kucharavy, Ljiljana Dolamic", "url": "https://api.semanticscholar.org/CorpusId:272423645", "relevance": 2, "abstract": "With the emergence of widely available powerful LLMs, disinformation generated by large Language Models (LLMs) has become a major concern. Historically, LLM detectors have been touted as a solution, but their effectiveness in the real world is still to be proven. In this paper, we focus on an important setting in information operations -- short news-like posts generated by moderately sophisticated attackers. We demonstrate that existing LLM detectors, whether zero-shot or purpose-trained, are not ready for real-world use in that setting. All tested zero-shot detectors perform inconsistently with prior benchmarks and are highly vulnerable to sampling temperature increase, a trivial attack absent from recent benchmarks. A purpose-trained detector generalizing across LLMs and unseen attacks can be developed, but it fails to generalize to new human-written texts. We argue that the former indicates domain-specific benchmarking is needed, while the latter suggests a trade-off between the adversarial evasion resilience and overfitting to the reference human text, with both needing evaluation in benchmarks and currently absent. We believe this suggests a re-consideration of current LLM detector benchmarking approaches and provides a dynamically extensible benchmark to allow it (https://github.com/Reliable-Information-Lab-HEVS/benchmark_llm_texts_detection).", "citations": 9}
{"title": "Between human and AI: assessing the reliability of AI text detection tools", "year": 2024, "authors": "Valentina Bellini, Federico Semeraro, J. Montomoli, M. Cascella, E. Bignami", "url": "https://www.semanticscholar.org/paper/84823c397546a517ccc189630f958ddf44e17715", "relevance": 2, "abstract": "Abstract Objective Large language models (LLMs) such as ChatGPT-4 have raised critical questions regarding their distinguishability from human-generated content. In this research, we evaluated the effectiveness of online detection tools in identifying ChatGPT-4 vs human-written text. Methods A two texts produced by ChatGPT-4 using differing prompts and one text created by a human author were analytically assessed using the following online detection tools: GPTZero, ZeroGPT, Writer ACD, and Originality. Results The findings revealed a notable variance in the detection capabilities of the employed detection tools. GPTZero and ZeroGPT exhibited inconsistent assessments regarding the AI-origin of the texts. Writer ACD predominantly identified texts as human-written, whereas Originality consistently recognized the AI-generated content in both samples from ChatGPT-4. This highlights Originality\u2019s enhanced sensitivity to patterns characteristic of AI-generated text. Conclusion The study demonstrates that while automatic detection tools may discern texts generated by ChatGPT-4 significant variability exists in their accuracy. Undoubtedly, there is an urgent need for advanced detection tools to ensure the authenticity and integrity of content, especially in scientific and academic research. However, our findings underscore an urgent need for more refined detection methodologies to prevent the misdetection of human-written content as AI-generated and vice versa.", "citations": 40}
{"title": "Evaluating Robustness of Neural Text Detectors in Generative AI Detection", "year": 2025, "authors": "Parasdeep, Mukesh Kumar Verma, Raghav Mehra, Kangan Soni, Maneesh Kumar", "url": "https://www.semanticscholar.org/paper/cad49cfaa2754833a625f50c7559fb30e8f4824d", "relevance": 2, "abstract": "Large language models (LLMs) such as GPT-3 and GPT-4 are now capable of producing text that can easily pass as human-written. While this has opened up exciting possibilities for automation, it has also created serious concerns for educators, researchers, and institutions that need to verify authorship. Existing detectors work reasonably well when analyzing unaltered text, but their performance falls apart once the text is paraphrased, reordered, or translated. In this work, we look closely at the strengths and weaknesses of five widely used detection tools, including Turnitin, GPTZero, Winston AI, and Originality.ai. To go beyond this evaluation, we also design a hybrid model that combines Logistic Regression with Random Forests using TF\u2013IDF features. The model was trained on a dataset of over 5,000 human-written and AI-generated samples. Unlike most commercial detectors, our system is open, reproducible, and lightweight. Results show that it loses far less accuracy under paraphrasing and translation, making it a more dependable option for institutions that need robust and transparent detection of AI-generated text.", "citations": 0}
{"title": "Detecting LLM-Generated Text in Computing Education: Comparative Study for ChatGPT Cases", "year": 2023, "authors": "Michael Sheinman Orenstrakh, Oscar Karnalim, C. Su\u00e1rez, Michael Liut", "url": "https://api.semanticscholar.org/CorpusId:259924631", "relevance": 1, "abstract": "Due to the recent improvements and wide availability of Large Language Models (LLMs), they have posed a serious threat to academic integrity in education. Modern LLM-generated text detectors attempt to combat the problem by offering educators with services to assess whether some text is LLM-generated. In this work, we have collected 124 submissions from computer science students before the creation of ChatGPT. We then generated 40 ChatGPT submissions. We used this data to evaluate eight publicly-available LLM-generated text detectors through the measures of accuracy, false positives, and resilience. Our results find that Copy Leaks is the most accurate LLM-generated text detector, G PTKit is the best LLM-generated text detector to reduce false positives, and GLTR is the most resilient LLM-generated text detector. We note that all LLM-generated text detectors are less accurate with code, other languages (aside from English), and after the use of paraphrasing tools.", "citations": 88}
{"title": "Raidar: geneRative AI Detection viA Rewriting", "year": 2024, "authors": "Chengzhi Mao, Carl Vondrick, Hao Wang, Junfeng Yang", "url": "https://api.semanticscholar.org/CorpusId:267095281", "relevance": 1, "abstract": "We find that large language models (LLMs) are more likely to modify human-written text than AI-generated text when tasked with rewriting. This tendency arises because LLMs often perceive AI-generated text as high-quality, leading to fewer modifications. We introduce a method to detect AI-generated content by prompting LLMs to rewrite text and calculating the editing distance of the output. We dubbed our geneRative AI Detection viA Rewriting method Raidar. Raidar significantly improves the F1 detection scores of existing AI content detection models -- both academic and commercial -- across various domains, including News, creative writing, student essays, code, Yelp reviews, and arXiv papers, with gains of up to 29 points. Operating solely on word symbols without high-dimensional features, our method is compatible with black box LLMs, and is inherently robust on new content. Our results illustrate the unique imprint of machine-generated text through the lens of the machines themselves.", "citations": 56}
{"title": "Robustness of generative AI detection: adversarial attacks on black-box neural text detectors", "year": 2024, "authors": "Vitalii Fishchuk, Daniel Braun", "url": "https://api.semanticscholar.org/CorpusId:273420418", "relevance": 1, "abstract": "The increased quality and human-likeness of AI generated texts has resulted in a rising demand for neural text detectors, i.e. software that is able to detect whether a text was written by a human or generated by an AI. Such tools are often used in contexts where the use of AI is restricted or completely prohibited, e.g. in educational contexts. It is, therefore, important for the effectiveness of such tools that they are robust towards deliberate attempts to hide the fact that a text was generated by an AI. In this article, we investigate a broad range of adversarial attacks in English texts with six different neural text detectors, including commercial and research tools. While the results show that no detector is completely invulnerable to adversarial attacks, the latest generation of commercial detectors proved to be very robust and not significantly influenced by most of the evaluated attack strategies.", "citations": 4}
{"title": "A Ship of Theseus: Curious Cases of Paraphrasing in LLM-Generated Texts", "year": 2023, "authors": "Nafis Irtiza Tripto, Saranya Venkatraman, Dominik Macko, R\u00f3bert M\u00f3ro, Ivan Srba, Adaku Uchendu, Thai Le, Dongwon Lee", "url": "https://api.semanticscholar.org/CorpusId:265157457", "relevance": 1, "abstract": "In the realm of text manipulation and linguistic transformation, the question of authorship has been a subject of fascination and philosophical inquiry. Much like the Ship of Theseus paradox, which ponders whether a ship remains the same when each of its original planks is replaced, our research delves into an intriguing question: Does a text retain its original authorship when it undergoes numerous paraphrasing iterations? Specifically, since Large Language Models (LLMs) have demonstrated remarkable proficiency in both the generation of original content and the modification of human-authored texts, a pivotal question emerges concerning the determination of authorship in instances where LLMs or similar paraphrasing tools are employed to rephrase the text--i.e., whether authorship should be attributed to the original human author or the AI-powered tool. Therefore, we embark on a philosophical voyage through the seas of language and authorship to unravel this intricate puzzle. Using a computational approach, we discover that the diminishing performance in text classification models, with each successive paraphrasing iteration, is closely associated with the extent of deviation from the original author's style, thus provoking a reconsideration of the current notion of authorship.", "citations": 26}
{"title": "Beyond Lexical Boundaries: LLM-Generated Text Detection for Romanian Digital Libraries", "year": 2024, "authors": "Melania Nitu, Mihai Dasc\u0103lu", "url": "https://api.semanticscholar.org/CorpusId:267294743", "relevance": 1, "abstract": "Machine-generated content reshapes the landscape of digital information; hence, ensuring the authenticity of texts within digital libraries has become a paramount concern. This work introduces a corpus of approximately 60 k Romanian documents, including human-written samples as well as generated texts using six distinct Large Language Models (LLMs) and three different generation methods. Our robust experimental dataset covers five domains, namely books, news, legal, medical, and scientific publications. The exploratory text analysis revealed differences between human-authored and artificially generated texts, exposing the intricacies of lexical diversity and textual complexity. Since Romanian is a less-resourced language requiring dedicated detectors on which out-of-the-box solutions do not work, this paper introduces two techniques for discerning machine-generated texts. The first method leverages a Transformer-based model to categorize texts as human or machine-generated, while the second method extracts and examines linguistic features, such as identifying the top textual complexity indices via Kruskal\u2013Wallis mean rank and computes burstiness, which are further fed into a machine-learning model leveraging an extreme gradient-boosting decision tree. The methods show competitive performance, with the first technique\u2019s results outperforming the second one in two out of five domains, reaching an F1 score of 0.96. Our study also includes a text similarity analysis between human-authored and artificially generated texts, coupled with a SHAP analysis to understand which linguistic features contribute more to the classifier\u2019s decision.", "citations": 11}
{"title": "Defining the Boundaries of AI Use in Scientific Writing: A Comparative Review of Editorial Policies", "year": 2025, "authors": "Jina Yoo", "url": "https://api.semanticscholar.org/CorpusId:279334016", "relevance": 1, "abstract": "The rapid rise of generative artificial intelligence (AI) is fundamentally transforming the landscape of medical writing and publishing. In response, major academic organizations and high-impact journals have released guidelines addressing core ethical concerns, including authorship qualification, disclosure of AI use, and the attribution of accountability. This review analyzes and compares key statements from several international medical or scientific editors\u2019 organizations along with submission policies of major leading journals. It also evaluates the AI usage policy of the Journal of Korean Medical Science (JKMS), which presents one of the most specific frameworks among Korean journals, and offers suggestions for refinement. While most journals prohibit listing AI tools as authors, their stance on AI-assisted writing varies. JKMS aligns with international norms by prohibiting AI authorship and recommending that authors explicitly report the tool name, prompt, purpose, and scope of AI use. This policy demonstrates a flexible but principled approach to AI integration. The limitations of AI detection tools are also discussed. These tools often struggle with accuracy and bias, with known tendencies to misclassify human-written content as AI-generated. As such, sole reliance on detection tools is insufficient for editorial decisions. Instead, fostering a culture of ethical authorship and responsible disclosure remains essential. This review highlights the need for balanced policies that promote transparency without impeding innovation. By clarifying disclosure expectations and reinforcing human accountability, journals can guide the ethical use of AI in scientific writing and maintain the integrity of scholarly communication.", "citations": 20}
{"title": "Adapting to the Impact of AI in Scientific Writing: Balancing Benefits and Drawbacks while Developing Policies and Regulations", "year": 2023, "authors": "Ahmed S. Bahammam, Khaled Trabelsi, S. Pandi\u2011Perumal, Hiatham Jahrami", "url": "https://api.semanticscholar.org/CorpusId:259138789", "relevance": 1, "abstract": "This article examines the advantages and disadvantages of Large Language Models (LLMs) and Artificial Intelligence (AI) in research and education and proposes the urgent need for an international statement to guide their responsible use. LLMs and AI demonstrate remarkable natural language processing, data analysis, and decision-making capabilities, offering potential benefits such as improved efficiency and transformative solutions. However, concerns regarding ethical considerations, bias, fake publications, and malicious use also arise. The objectives of this paper are to critically evaluate the utility of LLMs and AI in research and education, call for discussions between stakeholders, and discuss the need for an international statement. We identify advantages such as data processing, task automation, and personalized experiences, alongside disadvantages like bias reinforcement, interpretability challenges, inaccurate reporting, and plagiarism. Stakeholders from academia, industry, government, and civil society must engage in open discussions to address the ethical, legal, and societal implications. The proposed international statement should emphasize transparency, accountability, ongoing research, and risk mitigation. Monitoring, evaluation, user education, and awareness are essential components. By fostering discussions and establishing guidelines, we can ensure the responsible and ethical development and use of LLMs and AI, maximizing benefits while minimizing risks.", "citations": 11}
{"title": "GPT-who: An Information Density-based Machine-Generated Text Detector", "year": 2023, "authors": "Saranya Venkatraman, Adaku Uchendu, Dongwon Lee", "url": "https://api.semanticscholar.org/CorpusId:263830440", "relevance": 1, "abstract": "The Uniform Information Density (UID) principle posits that humans prefer to spread information evenly during language production. We examine if this UID principle can help capture differences between Large Language Models (LLMs)-generated and human-generated texts. We propose GPT-who, the first psycholinguistically-inspired domain-agnostic statistical detector. This detector employs UID-based features to model the unique statistical signature of each LLM and human author for accurate detection. We evaluate our method using 4 large-scale benchmark datasets and find that GPT-who outperforms state-of-the-art detectors (both statistical-&non-statistical) such as GLTR, GPTZero, DetectGPT, OpenAI detector, and ZeroGPT by over $20$% across domains. In addition to better performance, it is computationally inexpensive and utilizes an interpretable representation of text articles. We find that GPT-who can distinguish texts generated by very sophisticated LLMs, even when the overlying text is indiscernible. UID-based measures for all datasets and code are available at https://github.com/saranya-venkatraman/gpt-who.", "citations": 55}
{"title": "A Survey on Detection of LLMs-Generated Content", "year": 2023, "authors": "Xianjun Yang, Liangming Pan, Xuandong Zhao, Haifeng Chen, L. Petzold, William Yang Wang, Wei Cheng", "url": "https://api.semanticscholar.org/CorpusId:264439179", "relevance": 1, "abstract": "The burgeoning capabilities of advanced large language models (LLMs) such as ChatGPT have led to an increase in synthetic content generation with implications across a variety of sectors, including media, cybersecurity, public discourse, and education. As such, the ability to detect LLMs-generated content has become of paramount importance. We aim to provide a detailed overview of existing detection strategies and benchmarks, scrutinizing their differences and identifying key challenges and prospects in the field, advocating for more adaptable and robust models to enhance detection accuracy. We also posit the necessity for a multi-faceted approach to defend against various attacks to counter the rapidly advancing capabilities of LLMs. To the best of our knowledge, this work is the first comprehensive survey on the detection in the era of LLMs. We hope it will provide a broad understanding of the current landscape of LLMs-generated content detection, offering a guiding reference for researchers and practitioners striving to uphold the integrity of digital information in an era increasingly dominated by synthetic content. The relevant papers are summarized and will be consistently updated at https://github.com/Xianjun-Yang/Awesome_papers_on_LLMs_detection.git.", "citations": 77}
{"title": "Detecting AI-Generated Texts in Cross-Domains", "year": 2024, "authors": "You Zhou, Jie Wang", "url": "https://api.semanticscholar.org/CorpusId:272732093", "relevance": 1, "abstract": "Existing tools to detect text generated by a large language model (LLM) have met with certain success, but their performance can drop when dealing with texts in new domains. To tackle this issue, we train a ranking classifier called RoBERTa-Ranker, a modified version of RoBERTa, as a baseline model using a dataset we constructed that includes a wider variety of texts written by humans and generated by various LLMs. We then present a method to fine-tune RoBERTa-Ranker that requires only a small amount of labeled data in a new domain. Experiments show that this fine-tuned domain-aware model outperforms the popular DetectGPT and GPTZero on both in-domain and cross-domain texts, where AI-generated texts may either be in a different domain or generated by a different LLM not used to generate the training datasets. This approach makes it feasible and economical to build a single system to detect AI-generated texts across various domains.", "citations": 6}
{"title": "Navigating the Shadows: Unveiling Effective Disturbances for Modern AI Content Detectors", "year": 2024, "authors": "Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-702, Chris Bamford, Devendra Singh, Diego Chaplot, John Kirchenbauer, Jonas Geiping, Yuxin Wen, Khalid Saifullah, Kezhi Kong, Kasun Fernando, Aniruddha Saha, Micah Goldblum, Tharindu Kumarage, Paras Sheth, Raha Moraffah, T. Lavergne, Tanguy Urvoy, Fran\u00e7ois Yvon, Mike Lewis, Yinhan Liu, Marjan Naman Goyal, Abdelrahman Ghazvininejad, Omer Mohamed, Levy, Gongbo Liang, Jesus Guerrero, I. Alsmadi, Myle Ott, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy", "url": "https://api.semanticscholar.org/CorpusId:270287536", "relevance": 1, "abstract": "With the launch of ChatGPT, large language models (LLMs) have attracted global attention. In the realm of article writing, LLMs have witnessed extensive utilization, giving rise to concerns related to intellectual property protection, personal privacy, and academic integrity. In response, AI-text detection has emerged to distinguish between human and machine-generated content. However, recent research indicates that these detection systems often lack robustness and struggle to effectively differentiate perturbed texts. Currently, there is a lack of systematic evaluations regarding detection performance in real-world applications, and a comprehensive examination of perturbation techniques and detector robustness is also absent. To bridge this gap, our work simulates real-world scenarios in both informal and professional writing, exploring the out-of-the-box performance of current detectors. Additionally, we have constructed 12 black-box text perturbation methods to assess the robustness of current detection models across various perturbation granularities. Furthermore, through adversarial learning experiments, we investigate the impact of perturbation data augmentation on the robustness of AI-text detectors. We have released our code and data at https://github.com/zhouying20/ai-text-detector-evaluation.", "citations": 2}
{"title": "EditLens: Quantifying the Extent of AI Editing in Text", "year": 2025, "authors": "Katherine Thai, Bradley Emi, Elyas Masrour, Mohit Iyyer", "url": "https://api.semanticscholar.org/CorpusId:281829771", "relevance": 1, "abstract": "A significant proportion of queries to large language models ask them to edit user-provided text, rather than generate new text from scratch. While previous work focuses on detecting fully AI-generated text, we demonstrate that AI-edited text is distinguishable from human-written and AI-generated text. First, we propose using lightweight similarity metrics to quantify the magnitude of AI editing present in a text given the original human-written text and validate these metrics with human annotators. Using these similarity metrics as intermediate supervision, we then train EditLens, a regression model that predicts the amount of AI editing present within a text. Our model achieves state-of-the-art performance on both binary (F1=94.7%) and ternary (F1=90.4%) classification tasks in distinguishing human, AI, and mixed writing. Not only do we show that AI-edited text can be detected, but also that the degree of change made by AI to human writing can be detected, which has implications for authorship attribution, education, and policy. Finally, as a case study, we use our model to analyze the effects of AI-edits applied by Grammarly, a popular writing assistance tool. To encourage further research, we commit to publicly releasing our models and dataset.", "citations": 4}
{"title": "BiScope: AI-generated Text Detection by Checking Memorization of Preceding Tokens", "year": 2024, "authors": "Hanxi Guo, Siyuan Cheng, Xiaolong Jin, Zhuo Zhang, Kaiyuan Zhang, Guanhong Tao, Guangyu Shen, Xiangyu Zhang", "url": "https://www.semanticscholar.org/paper/97649635b7b36352df5839ba5ed87e00e2430aeb", "relevance": 1, "abstract": "Detecting text generated by Large Language Models (LLMs) is a pressing need in order to identify and prevent misuse of these powerful models in a wide range of applications, which have highly undesirable consequences such as misinformation and academic dishonesty. Given a piece of subject text, many existing detection methods work by measuring the difficulty of LLM predicting the next token in the text from their prefix. In this paper, we make a critical observation that how well the current token\u2019s output logits memorizes the closely preceding input tokens also provides strong evidence. Therefore, we propose a novel bi-directional calculation method that measures the cross-entropy losses between an output logits and the ground-truth token (forward) and between the output logits and the immediately preceding input token (backward). A classifier is trained to make the final prediction based on the statistics of these losses. We evaluate our system, named B I S COPE , on texts generated by five latest commercial LLMs across five heterogeneous datasets, including both natural language and code. B I S COPE demonstrates superior detection accuracy and robustness compared to nine existing baseline methods, exceeding the state-of-the-art non-commercial methods\u2019 detection accuracy by over 0 . 30 F1 score, achieving over 0 . 95 detection F1 score on average. It also outperforms the best commercial tool GPTZero that is based on a commercial LLM trained with an enormous volume of data. Code is available at https://github.com/MarkGHX/BiScope .", "citations": 24}
{"title": "Accurately detecting AI text when ChatGPT is told to write like a chemist", "year": 2023, "authors": "H. Desaire, Aleesa E. Chua, Min-Gyu Kim, David C. Hua", "url": "https://api.semanticscholar.org/CorpusId:265164755", "relevance": 1, "abstract": "", "citations": 38}
