\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{kirchenbauer2023watermark,dathathri2024synthid}
\citation{mitchell2023detectgpt,bao2024fastdetectgpt}
\citation{he2023mgtbench}
\citation{xu2025rlhf}
\citation{kirk2024rlhf}
\citation{lee2024remodetect}
\citation{mitchell2023detectgpt}
\citation{chakraborty2023possibilities}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\citation{dugan2024raid}
\citation{he2023mgtbench,li2024mage}
\citation{mitchell2023detectgpt}
\citation{bao2024fastdetectgpt}
\citation{gehrmann2019gltr}
\citation{kirchenbauer2023watermark,dathathri2024synthid}
\citation{kirk2024rlhf}
\citation{ouyang2022instructgpt}
\citation{xu2025rlhf}
\citation{lee2024remodetect}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\newlabel{sec:related_work}{{2}{2}{Related Work}{section.2}{}}
\citation{chakraborty2023possibilities}
\citation{dugan2024raid}
\citation{he2023mgtbench}
\citation{li2024mage}
\citation{dugan2024raid}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Dataset composition. All texts are scientific abstracts from the \textsc  {RAID}\xspace  benchmark. Each model variant contributes 500 clean (unattacked) texts.\relax }}{3}{table.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:data}{{1}{3}{Dataset composition. All texts are scientific abstracts from the \raid benchmark. Each model variant contributes 500 clean (unattacked) texts.\relax }{table.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{3}{section.3}\protected@file@percent }
\newlabel{sec:methodology}{{3}{3}{Methodology}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data}{3}{subsection.3.1}\protected@file@percent }
\newlabel{sec:data}{{3.1}{3}{Data}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Experiment 1: Distributional Feature Analysis}{3}{subsection.3.2}\protected@file@percent }
\newlabel{sec:exp1}{{3.2}{3}{Experiment 1: Distributional Feature Analysis}{subsection.3.2}{}}
\citation{mitchell2023detectgpt,bao2024fastdetectgpt}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Experiment 2: Zero-Shot Statistical Detection}{4}{subsection.3.3}\protected@file@percent }
\newlabel{sec:exp2}{{3.3}{4}{Experiment 2: Zero-Shot Statistical Detection}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Experiment 3: LLM-as-Detector}{4}{subsection.3.4}\protected@file@percent }
\newlabel{sec:exp3}{{3.4}{4}{Experiment 3: LLM-as-Detector}{subsection.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Experiment 4: Cross-Family Consistency}{4}{subsection.3.5}\protected@file@percent }
\newlabel{sec:exp4}{{3.5}{4}{Experiment 4: Cross-Family Consistency}{subsection.3.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{4}{section.4}\protected@file@percent }
\newlabel{sec:results}{{4}{4}{Results}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Alignment Shifts Text Distributions (Experiment 1)}{4}{subsection.4.1}\protected@file@percent }
\newlabel{sec:results_exp1}{{4.1}{4}{Alignment Shifts Text Distributions (Experiment 1)}{subsection.4.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Cohen's $d$ effect sizes for base vs.\ aligned distributional features within each model family. Positive values indicate aligned $>$ base. Bold entries mark features that shift consistently across all families. Alignment consistently reduces sentence-length variability and text length.\relax }}{5}{table.caption.3}\protected@file@percent }
\newlabel{tab:effect_sizes}{{2}{5}{Cohen's $d$ effect sizes for base vs.\ aligned distributional features within each model family. Positive values indicate aligned $>$ base. Bold entries mark features that shift consistently across all families. Alignment consistently reduces sentence-length variability and text length.\relax }{table.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Alignment Dramatically Increases Statistical Detectability (Experiment 2)}{5}{subsection.4.2}\protected@file@percent }
\newlabel{sec:results_exp2}{{4.2}{5}{Alignment Dramatically Increases Statistical Detectability (Experiment 2)}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}LLMs Detect Aligned Text Near-Perfectly (Experiment 3)}{5}{subsection.4.3}\protected@file@percent }
\newlabel{sec:results_exp3}{{4.3}{5}{LLMs Detect Aligned Text Near-Perfectly (Experiment 3)}{subsection.4.3}{}}
\citation{kirk2024rlhf}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces AUROC for distinguishing human text from AI text using zero-shot statistical detection signals. Aligned models are substantially more detectable than base models across all families and primary signals. Best results per row in \textbf  {bold}.\relax }}{6}{table.caption.4}\protected@file@percent }
\newlabel{tab:auroc}{{3}{6}{AUROC for distinguishing human text from AI text using zero-shot statistical detection signals. Aligned models are substantially more detectable than base models across all families and primary signals. Best results per row in \textbf {bold}.\relax }{table.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces \textsc  {GPT-4.1}\xspace  detection performance by model family. TPR is the rate at which AI text is correctly classified as AI. Human text TNR is 56.2\%. Aligned models are detected at higher rates than base models, significantly so for Mistral and MPT. Best per-family results in \textbf  {bold}.\relax }}{6}{table.caption.5}\protected@file@percent }
\newlabel{tab:llm_detector}{{4}{6}{\gptfour detection performance by model family. TPR is the rate at which AI text is correctly classified as AI. Human text TNR is 56.2\%. Aligned models are detected at higher rates than base models, significantly so for Mistral and MPT. Best per-family results in \textbf {bold}.\relax }{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}The Alignment Watermark Generalizes Across Families (Experiment 4)}{6}{subsection.4.4}\protected@file@percent }
\newlabel{sec:results_exp4}{{4.4}{6}{The Alignment Watermark Generalizes Across Families (Experiment 4)}{subsection.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{6}{section.5}\protected@file@percent }
\newlabel{sec:discussion}{{5}{6}{Discussion}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}The Mechanism: Structural Regularity}{6}{subsection.5.1}\protected@file@percent }
\newlabel{sec:mechanism}{{5.1}{6}{The Mechanism: Structural Regularity}{subsection.5.1}{}}
\citation{xu2025rlhf}
\citation{kirk2024rlhf}
\citation{xu2025rlhf}
\citation{kirk2024rlhf}
\citation{lee2024remodetect}
\citation{guo2023hc3}
\citation{xu2025rlhf}
\citation{xu2025rlhf}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Cross-family consistency of the alignment watermark. \text  {$\mathsurround \z@ \mathchar "458$}\ indicates aligned AUROC/TPR $>$ base. 11 of 12 comparisons show aligned $>$ base (sign test $p = 0.006$).\relax }}{7}{table.caption.6}\protected@file@percent }
\newlabel{tab:consistency}{{5}{7}{Cross-family consistency of the alignment watermark. \checkmark \ indicates aligned AUROC/TPR $>$ base. 11 of 12 comparisons show aligned $>$ base (sign test $p = 0.006$).\relax }{table.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Comparison to prior work. Our results extend single-family findings to a cross-family setting.\relax }}{7}{table.caption.7}\protected@file@percent }
\newlabel{tab:comparison}{{6}{7}{Comparison to prior work. Our results extend single-family findings to a cross-family setting.\relax }{table.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Comparison to Prior Work}{7}{subsection.5.2}\protected@file@percent }
\newlabel{sec:comparison}{{5.2}{7}{Comparison to Prior Work}{subsection.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Why Cohere Differs}{7}{subsection.5.3}\protected@file@percent }
\newlabel{sec:cohere}{{5.3}{7}{Why Cohere Differs}{subsection.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}The GPT-4.1 False Positive Problem}{7}{subsection.5.4}\protected@file@percent }
\newlabel{sec:false_positives}{{5.4}{7}{The GPT-4.1 False Positive Problem}{subsection.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Limitations}{7}{subsection.5.5}\protected@file@percent }
\newlabel{sec:limitations}{{5.5}{7}{Limitations}{subsection.5.5}{}}
\citation{mitchell2023detectgpt,bao2024fastdetectgpt}
\bibstyle{plainnat}
\bibdata{references}
\bibcite{bao2024fastdetectgpt}{{1}{2024}{{Bao et~al.}}{{Bao, Zhao, Teng, Yang, and Zhang}}}
\bibcite{chakraborty2023possibilities}{{2}{2023}{{Chakraborty et~al.}}{{Chakraborty, Bedi, Zhu, An, Manocha, and Huang}}}
\bibcite{dathathri2024synthid}{{3}{2024}{{Dathathri et~al.}}{{Dathathri, See, Ghaisas, Huang, McAdam, Welbl, Bachani, Krawczuk, Mayber, Puri, et~al.}}}
\bibcite{dugan2024raid}{{4}{2024}{{Dugan et~al.}}{{Dugan, Hwang, Trhl{\'i}k, Ludan, Ippolito, and Callison-Burch}}}
\bibcite{gehrmann2019gltr}{{5}{2019}{{Gehrmann et~al.}}{{Gehrmann, Strobelt, and Rush}}}
\bibcite{guo2023hc3}{{6}{2023}{{Guo et~al.}}{{Guo, Zhang, Wang, Jiang, Nie, Ding, Yue, and Wu}}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{8}{section.6}\protected@file@percent }
\newlabel{sec:conclusion}{{6}{8}{Conclusion}{section.6}{}}
\bibcite{he2023mgtbench}{{7}{2024}{{He et~al.}}{{He, Shen, Chen, Backes, and Zhang}}}
\bibcite{kirchenbauer2023watermark}{{8}{2023}{{Kirchenbauer et~al.}}{{Kirchenbauer, Geiping, Wen, Katz, Miers, and Goldstein}}}
\bibcite{kirk2024rlhf}{{9}{2024}{{Kirk et~al.}}{{Kirk, Mediratta, Nalmpantis, Luketina, Hambro, Grefenstette, and Raileanu}}}
\bibcite{lee2024remodetect}{{10}{2024}{{Lee et~al.}}{{Lee, Tack, and Shin}}}
\bibcite{li2024mage}{{11}{2024}{{Li et~al.}}{{Li, Li, Cui, Bi, Wang, Wang, Kong, Quan, Shi, Zhang, et~al.}}}
\bibcite{mitchell2023detectgpt}{{12}{2023}{{Mitchell et~al.}}{{Mitchell, Lee, Khazatsky, Manning, and Finn}}}
\bibcite{ouyang2022instructgpt}{{13}{2022}{{Ouyang et~al.}}{{Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin, Zhang, Agarwal, Slama, Ray, et~al.}}}
\bibcite{xu2025rlhf}{{14}{2025}{{Xu and Zubiaga}}{{}}}
\citation{dugan2024raid}
\@writefile{toc}{\contentsline {section}{\numberline {A}Reproducibility}{10}{appendix.A}\protected@file@percent }
\newlabel{sec:reproducibility}{{A}{10}{Reproducibility}{appendix.A}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Hyperparameters used across all experiments.\relax }}{10}{table.caption.9}\protected@file@percent }
\newlabel{tab:hyperparams}{{7}{10}{Hyperparameters used across all experiments.\relax }{table.caption.9}{}}
\gdef \@abspage@last{10}
