# RAID Dataset for Alignment Watermark Research

## Overview

The [RAID dataset](https://huggingface.co/datasets/liamdugan/raid) (Robust AI-text Detection) is the
primary dataset for this research project because it contains **explicit base/chat model pairs**:

| Base Model | Chat/Aligned Model | Available |
|------------|-------------------|-----------|
| Mistral    | Mistral-Chat      | Yes (500 each) |
| MPT        | MPT-Chat          | Yes (500 each) |
| Cohere     | Cohere-Chat       | Yes (500 each) |

These pairs allow direct comparison of text generated by base models vs. their alignment-tuned
counterparts, which is exactly what we need to study alignment watermarks.

## Dataset Structure

**HuggingFace:** `liamdugan/raid`

### Configs and Splits

| Config | Split | Content |
|--------|-------|---------|
| `raid` (default) | `train` | Labeled data with model attribution (abstracts domain) |
| `raid` (default) | `extra` | Additional domains: code, german, czech |
| `raid_test` | `test` | Blind test set (id + generation only, no labels) |

### Columns (train/extra splits)

- `id` - Unique identifier
- `model` - Source model name (e.g., "mistral", "mistral-chat", "human")
- `decoding` - Decoding strategy ("greedy" or "sampling", None for human)
- `repetition_penalty` - Repetition penalty used (None for human)
- `attack` - Adversarial attack applied ("none", "whitespace", "synonym", etc.)
- `domain` - Text domain ("abstracts", "code", "german", "czech")
- `title` - Title/prompt context
- `prompt` - Full prompt (None for human)
- `generation` - The generated text

### Models in Dataset

**Train split (abstracts domain):**
- `human` - Human-written text (ground truth)
- `gpt2` - GPT-2 (base model, no chat variant)
- `mistral` / `mistral-chat` - **BASE/CHAT PAIR**
- `mpt` / `mpt-chat` - **BASE/CHAT PAIR**
- `cohere` / `cohere-chat` - **BASE/CHAT PAIR**
- `llama-chat` - LLaMA Chat (no base variant in dataset)
- `chatgpt` - ChatGPT
- `gpt3` - GPT-3
- `gpt4` - GPT-4

**Extra split (code, german, czech domains):**
- `human`, `gpt2`, `mistral`, `mistral-chat`, `mpt`, `mpt-chat`, `llama-chat`

## Downloaded Files

### Core pair files (for watermark analysis)
- `pair_mistral.json` - 500 base + 500 chat samples (1.9 MB)
- `pair_mpt.json` - 500 base + 500 chat samples (2.0 MB)
- `pair_cohere.json` - 500 base + 500 chat samples (1.6 MB)

### Complete sample files
- `raid_clean_samples.json` - 6,000 samples (500 per model, attack='none' only, abstracts domain) (11 MB)
- `raid_extra_samples.json` - 2,100 samples (100 per model/domain from extra split) (3.8 MB)

### Metadata
- `dataset_summary.json` - Summary statistics
- `model_summary.json` - Model counts from initial exploration
- `samples_by_model.json` - 3 example samples per model
- `samples.json` - First 10 raw samples for inspection

## Download Instructions

### Quick: Load from HuggingFace (streaming)

```python
from datasets import load_dataset

# Stream the train split (abstracts)
ds = load_dataset("liamdugan/raid", split="train", streaming=True)

# Stream the extra split (code, german, czech)
ds_extra = load_dataset("liamdugan/raid", split="extra", streaming=True)

# Filter for specific model pair
for item in ds:
    if item['model'] in ('mistral', 'mistral-chat') and item['attack'] == 'none':
        # Process item
        pass
```

### Full download (WARNING: dataset is very large)

```python
# This will download the full dataset to disk (~several GB)
ds = load_dataset("liamdugan/raid", split="train")

# Filter to just base/chat pairs
pairs = ds.filter(lambda x: x['model'] in ('mistral', 'mistral-chat') and x['attack'] == 'none')
```

### Re-run the download scripts

```bash
# Activate the project venv
source /workspaces/alignment-watermark-0988-claude/.venv/bin/activate

# Download 500 samples per model from train split (clean/non-attacked only)
python /workspaces/alignment-watermark-0988-claude/datasets/raid/download_pairs.py

# Download 100 samples per model/domain from extra split
python /workspaces/alignment-watermark-0988-claude/datasets/raid/download_extra_domains.py
```

## Key Statistics

- **Total samples downloaded:** 8,100 (6,000 train + 2,100 extra)
- **Base/chat pairs:** 3 (Mistral, MPT, Cohere) with 500 samples each side
- **Domains covered:** abstracts, code, german, czech
- **All samples are clean** (attack='none') to avoid confounding adversarial modifications with alignment signals
- **Decoding split:** Each model has equal greedy and sampling generations (250 each)

## Relevance to Alignment Watermark Research

The base/chat pairs are critical because:

1. **Same architecture, different training** - Base and chat models share the same architecture
   but differ in alignment training (RLHF, instruction tuning, etc.)
2. **Controlled comparison** - Text generated from the same prompts/domains allows isolating
   the effect of alignment on linguistic patterns
3. **Multiple model families** - Three independent pairs (Mistral, MPT, Cohere) allow testing
   whether alignment watermarks generalize across architectures
4. **Human baseline** - Human-written text provides the ground truth for comparison
